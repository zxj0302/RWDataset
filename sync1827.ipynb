{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.io as scio\n",
    "from torch_geometric.data import Data\n",
    "import torch\n",
    "import os\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_list = torch.load('pretrain_desco.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use EVOKE to compute ground truth\n",
    "# 2.1 generate edge_list files EVOKE needs \n",
    "edgelist_graph_path = 'evoke/wrappers/edgelist_graph'\n",
    "if not os.path.exists(edgelist_graph_path):\n",
    "    os.mkdir(edgelist_graph_path)\n",
    "for i, g in tqdm(enumerate(data_list), total=len(data_list), desc='Generating edge list files'):\n",
    "    with open(f'{edgelist_graph_path}/rw_{i}.edgelist', 'w') as f:\n",
    "        f.write(f'{g.num_nodes} {g.num_edges//2}\\n')\n",
    "        for edge in g.edge_index.T:\n",
    "            if edge[0] < edge[1]:\n",
    "                f.write(f'{edge[0]} {edge[1]}\\n')\n",
    "print('Edge list files generated')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Adding ground truth to graphs: 1827it [00:01, 1737.42it/s]\n"
     ]
    }
   ],
   "source": [
    "# 2.2 compute the ground truth using 'run_ego.py' with EVOKE\n",
    "output_evoke_path = 'evoke/wrappers/output_evoke'\n",
    "output_graph_path = 'evoke/wrappers/output_graph'\n",
    "# evoke_wrappers_path = 'evoke/wrappers/'\n",
    "# run_evoke_name = 'run_evoke.py'\n",
    "# if not os.path.exists(output_evoke_path):\n",
    "#     os.mkdir(output_evoke_path)\n",
    "# if os.path.exists(output_graph_path):\n",
    "#     os.mkdir(output_graph_path)\n",
    "# # run the EVOKE to compute the ground truth\n",
    "# os.system(f'cd {evoke_wrappers_path} && python {run_evoke_name} graph')\n",
    "# read in the ground truth and add gt_induced_le5 & gt_noninduced_le5 to the graphs\n",
    "for i, g in tqdm(enumerate(data_list), desc='Adding ground truth to graphs'):\n",
    "    induced = torch.load(f'{output_graph_path}/induced_rw_{i}.pt')\n",
    "    g.gt_induced_le5 = induced"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = {\n",
    "    'train': data_list,\n",
    "    'val': data_list,\n",
    "    'test': data_list\n",
    "}\n",
    "torch.save(dataset, 'pretrain_desco.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "for g in data_list:\n",
    "    g.y = g.gt_induced_le5[:, 1:]\n",
    "    del g.gt_induced_le5\n",
    "    g.x = torch.ones(g.num_nodes, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.]]) tensor([[25, 20,  0, 25,  0, 43, 39, 13,  0,  0, 11,  0,  0, 31,  0,  0, 52,  5,\n",
      "          0,  0,  0, 17, 10, 21,  0, 43,  4, 13,  3],\n",
      "        [16,  3,  5, 23,  0, 26, 11,  1,  6,  5, 12,  9,  1, 29,  0,  1, 37,  6,\n",
      "          0,  0,  1, 10,  4,  8,  0, 14,  0,  2,  0],\n",
      "        [15,  1,  2, 27,  0, 23,  7,  0,  0,  4, 12,  6,  0, 42,  0,  1, 36,  0,\n",
      "          0,  0,  0, 11,  6,  2,  0, 10,  0,  0,  0],\n",
      "        [16,  8,  9, 12,  2, 28, 18,  5,  7,  2,  5,  7,  3, 19,  1,  2, 36,  5,\n",
      "          3,  0,  3,  5,  9, 14,  1, 16,  4,  8,  1],\n",
      "        [16,  2, 14, 14,  2, 25,  9,  0,  5,  8,  8, 18,  2, 14,  1,  4, 34,  1,\n",
      "          4,  0,  6,  3,  7, 14,  1,  9,  2,  0,  0],\n",
      "        [17, 11,  6, 11,  3, 29, 22,  8,  3,  1,  5, 10,  1, 13,  0,  3, 41,  1,\n",
      "          3,  0,  4,  5, 10, 10,  2, 24,  5, 10,  2],\n",
      "        [21, 18,  6, 14,  1, 39, 32, 13,  0,  5,  3, 14,  1, 18,  0,  1, 36,  4,\n",
      "          4,  0,  4, 14, 13, 13,  1, 40,  3, 13,  3],\n",
      "        [18,  9, 16,  8,  2, 36, 19,  5,  9,  5,  0, 12,  4, 21,  1,  3, 26, 10,\n",
      "          3,  0,  8,  5,  5, 23,  1, 26,  2,  5,  1],\n",
      "        [17, 10, 12,  9,  3, 34, 18,  7,  5,  4,  2, 10,  3, 21,  1,  4, 26,  7,\n",
      "          3,  0,  7,  5, 12, 15,  2, 24,  4,  6,  2],\n",
      "        [17,  8,  8, 14,  2, 28, 19,  5,  4,  4,  7, 10,  1, 19,  1,  1, 38,  3,\n",
      "          3,  0,  4,  6,  5, 11,  1, 22,  4,  7,  1],\n",
      "        [14,  9,  6, 11,  1, 33, 14,  7,  6,  2,  5,  9,  4, 23,  0,  0, 28,  8,\n",
      "          2,  0,  3,  4, 14,  9,  1, 22,  2,  6,  2]])\n"
     ]
    }
   ],
   "source": [
    "print(data_list[1].x, data_list[1].y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dict = [g.to_dict() for g in data_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_compatible = {\n",
    "    'train': data_dict,\n",
    "    'val': data_dict,\n",
    "    'test': data_dict\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'dataset_compatible' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28mprint\u001b[39m(dataset_compatible[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;241m2\u001b[39m])\n",
      "\u001b[1;31mNameError\u001b[0m: name 'dataset_compatible' is not defined"
     ]
    }
   ],
   "source": [
    "print(dataset_compatible['train'][2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(dataset_compatible, 'dataset_compatible.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_compatible = torch.load('dataset_compatible.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'x': tensor([[1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.]]), 'edge_index': tensor([[ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  1,  1,  1,  2,  2,  3,  3,  3,\n",
      "          3,  3,  4,  4,  4,  5,  5,  5,  5,  5,  5,  6,  6,  6,  6,  6,  6,  6,\n",
      "          6,  6,  7,  7,  7,  7,  7,  7,  8,  8,  8,  8,  8,  8,  9,  9,  9,  9,\n",
      "          9, 10, 10, 10, 10, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10,  0,  6,  7,  0,  6,  0,  6,  8,\n",
      "          9, 10,  0,  7,  8,  0,  6,  7,  8,  9, 10,  0,  1,  2,  3,  5,  7,  8,\n",
      "          9, 10,  0,  1,  4,  5,  6,  9,  0,  3,  4,  5,  6, 10,  0,  3,  5,  6,\n",
      "          7,  0,  3,  5,  6,  8]]), 'y': tensor([[25, 20,  0, 25,  0, 43, 39, 13,  0,  0, 11,  0,  0, 31,  0,  0, 52,  5,\n",
      "          0,  0,  0, 17, 10, 21,  0, 43,  4, 13,  3],\n",
      "        [16,  3,  5, 23,  0, 26, 11,  1,  6,  5, 12,  9,  1, 29,  0,  1, 37,  6,\n",
      "          0,  0,  1, 10,  4,  8,  0, 14,  0,  2,  0],\n",
      "        [15,  1,  2, 27,  0, 23,  7,  0,  0,  4, 12,  6,  0, 42,  0,  1, 36,  0,\n",
      "          0,  0,  0, 11,  6,  2,  0, 10,  0,  0,  0],\n",
      "        [16,  8,  9, 12,  2, 28, 18,  5,  7,  2,  5,  7,  3, 19,  1,  2, 36,  5,\n",
      "          3,  0,  3,  5,  9, 14,  1, 16,  4,  8,  1],\n",
      "        [16,  2, 14, 14,  2, 25,  9,  0,  5,  8,  8, 18,  2, 14,  1,  4, 34,  1,\n",
      "          4,  0,  6,  3,  7, 14,  1,  9,  2,  0,  0],\n",
      "        [17, 11,  6, 11,  3, 29, 22,  8,  3,  1,  5, 10,  1, 13,  0,  3, 41,  1,\n",
      "          3,  0,  4,  5, 10, 10,  2, 24,  5, 10,  2],\n",
      "        [21, 18,  6, 14,  1, 39, 32, 13,  0,  5,  3, 14,  1, 18,  0,  1, 36,  4,\n",
      "          4,  0,  4, 14, 13, 13,  1, 40,  3, 13,  3],\n",
      "        [18,  9, 16,  8,  2, 36, 19,  5,  9,  5,  0, 12,  4, 21,  1,  3, 26, 10,\n",
      "          3,  0,  8,  5,  5, 23,  1, 26,  2,  5,  1],\n",
      "        [17, 10, 12,  9,  3, 34, 18,  7,  5,  4,  2, 10,  3, 21,  1,  4, 26,  7,\n",
      "          3,  0,  7,  5, 12, 15,  2, 24,  4,  6,  2],\n",
      "        [17,  8,  8, 14,  2, 28, 19,  5,  4,  4,  7, 10,  1, 19,  1,  1, 38,  3,\n",
      "          3,  0,  4,  6,  5, 11,  1, 22,  4,  7,  1],\n",
      "        [14,  9,  6, 11,  1, 33, 14,  7,  6,  2,  5,  9,  4, 23,  0,  0, 28,  8,\n",
      "          2,  0,  3,  4, 14,  9,  1, 22,  2,  6,  2]])}\n"
     ]
    }
   ],
   "source": [
    "print(dataset_compatible['train'][1])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
