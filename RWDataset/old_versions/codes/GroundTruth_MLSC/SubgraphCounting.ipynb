{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "TODO:\n",
    "1. 模块化print和log， 并可视化, log 2 a file\n",
    "2. 合理规划生成的数据文件的命名\n",
    "3. 查看并行化的bug以及batch_size的设置\n",
    "4. 优化传入的参数\n",
    "5. 修改GIN，看里面用的几层MLP\n",
    "6. settle down all random seeds\n",
    "7. change output to positive integer\n",
    "8. change labels to log scale\n",
    "9. make tqdm runs well with multiprocessing\n",
    "10. figure out why the slp is not updated\n",
    "11. find good ways to visualize the computation graph"
   ],
   "id": "7cc8943655aa8d9b"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-28T09:50:22.098202Z",
     "start_time": "2024-06-28T09:50:16.716599Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch_geometric.datasets as datasets\n",
    "from torch_geometric.nn.models import GIN, MLP\n",
    "import pytorch_lightning as pl\n",
    "from pytorch_lightning import loggers\n",
    "from torch_geometric.data import Data\n",
    "from torch_geometric.loader import DataLoader\n",
    "from pytorch_lightning.callbacks import StochasticWeightAveraging\n",
    "from tqdm.notebook import tqdm\n",
    "import networkx as nx\n",
    "from torch_geometric.utils import to_networkx\n",
    "from torch.utils.data import random_split\n",
    "from torchviz import make_dot\n",
    "import os"
   ],
   "id": "b2877883420ca700",
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-28T09:50:22.115093Z",
     "start_time": "2024-06-28T09:50:22.099582Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class ENDataModule(pl.LightningDataModule):\n",
    "    def __init__(self, dataset_list, queries, train_valid_test=(0.7, 0.2, 0.1), hop=3, batch_s=64, num_workers=8):\n",
    "        super().__init__()\n",
    "        self.save_hyperparameters()\n",
    "        self.dataset_list = dataset_list\n",
    "        self.query_graph = queries\n",
    "        self.train_valid_test = train_valid_test\n",
    "        self.hop = hop\n",
    "        self.batch_size = batch_s\n",
    "        self.num_workers = num_workers\n",
    "        self.dataset_source = {'IMDB-BINARY': 'TUDataset', 'PTC_MR': 'TUDataset', 'PROTEINS': 'TUDataset',\n",
    "                               'NCI1': 'TUDataset', 'NCI109': 'TUDataset', 'MUTAG': 'TUDataset', 'ENZYMES': 'TUDataset',\n",
    "                               'DD': 'TUDataset', 'COLLAB': 'TUDataset', 'REDDIT-BINARY': 'TUDataset',\n",
    "                               'REDDIT-MULTI-5K': 'TUDataset', 'REDDIT-MULTI-12K': 'TUDataset', 'QM9': 'TUDataset',\n",
    "                               'FIRSTMM_DB': 'TUDataset', 'ZINC': 'TUDataset', 'Cora': 'Planetoid',\n",
    "                               'CiteSeer': 'Planetoid', 'PubMed': 'Planetoid'}\n",
    "        # just assume the 'query_graph' contains only one graph and the file_path is not valid on Windows System\n",
    "        # the query_graph must contain an attribute 'name'\n",
    "        self.file_path = 'data/ENDataset/' + '&'.join(sorted(dataset_list)) + '@' + '&'.join(sorted(qg.graph['name'] for qg in self.query_graph)) + '.pt'\n",
    "        self.processed_data, self.raw_data, self.train_dataset, self.val_dataset, self.test_dataset = (None,) * 5\n",
    "\n",
    "    def prepare_data(self):\n",
    "        for ds in self.dataset_list:\n",
    "            if ds not in self.dataset_source:\n",
    "                raise ValueError(f'Dataset {ds} not included')\n",
    "            else:\n",
    "                getattr(datasets, self.dataset_source[ds])(f'data/{self.dataset_source[ds]}', ds)\n",
    "\n",
    "    def setup(self, stage=None):\n",
    "        if os.path.exists(self.file_path):\n",
    "            self.processed_data = torch.load(self.file_path)\n",
    "        else:\n",
    "            self.raw_data = [(getattr(datasets, self.dataset_source[ds])(f'data/{self.dataset_source[ds]}', ds)) for ds in self.dataset_list]\n",
    "            self.dataset_generator()\n",
    "\n",
    "            # save the dataset to file and print information\n",
    "            torch.save(self.processed_data, self.file_path)\n",
    "            print('File saved to ', self.file_path)\n",
    "\n",
    "        # split the dataset\n",
    "        self.train_dataset, self.val_dataset, self.test_dataset = random_split(self.processed_data,\n",
    "                                                                               self.train_valid_test)\n",
    "\n",
    "    def train_dataloader(self):\n",
    "        return DataLoader(self.train_dataset, batch_size=self.batch_size, num_workers=self.num_workers,\n",
    "                          persistent_workers=True, shuffle=True, pin_memory=True, drop_last=True)\n",
    "\n",
    "    def val_dataloader(self):\n",
    "        return DataLoader(self.val_dataset, batch_size=self.batch_size, num_workers=self.num_workers,\n",
    "                          persistent_workers=True, pin_memory=True, drop_last=True)\n",
    "\n",
    "    def test_dataloader(self):\n",
    "        return DataLoader(self.test_dataset, batch_size=self.batch_size, num_workers=self.num_workers,\n",
    "                          persistent_workers=True, pin_memory=True, drop_last=True)\n",
    "\n",
    "    def predict_dataloader(self):\n",
    "        pass\n",
    "\n",
    "    def dataset_generator(self):\n",
    "        num_automorphisms = []\n",
    "        for query_graph_ in self.query_graph:\n",
    "            num_automorphism_per = 0\n",
    "            for _ in nx.algorithms.isomorphism.GraphMatcher(query_graph_, query_graph_).subgraph_isomorphisms_iter():\n",
    "                num_automorphism_per += 1\n",
    "            num_automorphisms.append(num_automorphism_per)\n",
    "        print(\"Number of automorphism of query graphs: \", num_automorphisms)\n",
    "\n",
    "        data_list, all_tasks = [], []\n",
    "        for raw in self.raw_data:\n",
    "            for graph in raw:\n",
    "                graph = to_networkx(graph, to_undirected=True)\n",
    "                for node in graph.nodes():\n",
    "                    ego = nx.ego_graph(graph, node, radius=self.hop)\n",
    "                    all_tasks.append((ego, node, num_automorphisms))\n",
    "        print(f'{len(all_tasks)} tasks submitted')\n",
    "\n",
    "        for task in tqdm(all_tasks, total=len(all_tasks)):\n",
    "            data_list.append(self.dataset_generator_per(task))\n",
    "\n",
    "        self.processed_data = data_list\n",
    "\n",
    "    def dataset_generator_per(self, task):\n",
    "        ego, central_node, num_automorphisms = task\n",
    "\n",
    "        # compute the subgraph counts for each query graph\n",
    "        item_y = []\n",
    "        for it in range(len(self.query_graph)):\n",
    "            item_y_per = 0\n",
    "            for i in nx.algorithms.isomorphism.GraphMatcher(ego, self.query_graph[it]).subgraph_isomorphisms_iter():\n",
    "                if central_node in i.keys():\n",
    "                    item_y_per += 1\n",
    "            item_y.append(item_y_per / num_automorphisms[it])\n",
    "\n",
    "        # convert the ego network to torch_geometric.data.Data object and set the node 0 as central node\n",
    "        mapping = {central_node: 0}\n",
    "        for n in ego.nodes():\n",
    "            if n != central_node:\n",
    "                mapping[n] = len(mapping)\n",
    "        ego = nx.relabel_nodes(ego, mapping)\n",
    "        # get the edge_index with COO format, be careful with the condition of empty edges\n",
    "        edges = sorted([(e[0], e[1]) for e in ego.edges()] + [(e[1], e[0]) for e in ego.edges()],\n",
    "                       key=lambda x: (x[0], x[1]))\n",
    "        edge_index = torch.tensor([[], []], dtype=torch.long) if not edges else torch.tensor(edges,\n",
    "                                                                                             dtype=torch.long).t().contiguous()\n",
    "        data = Data(x=torch.ones(len(ego), 1, dtype=torch.float32), edge_index=edge_index,\n",
    "                    y=torch.tensor(item_y, dtype=torch.float32))\n",
    "\n",
    "        return data"
   ],
   "id": "8f9503e77672f210",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-28T09:50:22.125335Z",
     "start_time": "2024-06-28T09:50:22.116588Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class Model(pl.LightningModule):\n",
    "    def __init__(self, in_channels, hidden_channels=64, out_channels=32, num_layers=1, dropout=0.1, batch_s=512, lr=0.01):\n",
    "        super().__init__()\n",
    "        self.save_hyperparameters()\n",
    "        self.gin = GIN(in_channels, hidden_channels, num_layers, out_channels, dropout, train_eps=True)#normalization\n",
    "        self.slp = MLP([1, out_channels])\n",
    "        self.mlp = MLP([out_channels * 2, out_channels, out_channels, 1], dropout=dropout)\n",
    "\n",
    "        # compute the difference between the two vectors y_hat and y as loss function\n",
    "        self.loss = nn.L1Loss()\n",
    "        self.batch_size = batch_s\n",
    "        self.lr = lr\n",
    "\n",
    "    def forward(self, x, edge_index, batch):\n",
    "        index = torch.cat([torch.tensor([0], device=self.device), batch.long().bincount().cumsum(dim=0)])[:-1]\n",
    "        x = self.gin(x, edge_index)\n",
    "        x = x[index]\n",
    "        x_sub = self.slp(torch.ones(x.size(0), 1, device=self.device))\n",
    "        x = torch.cat([x, x_sub], dim=1)\n",
    "        x = self.mlp(x).reshape(-1)\n",
    "        x = torch.relu(x)\n",
    "        # x = torch.round(x)\n",
    "        return x\n",
    "\n",
    "    def training_step(self, data, batch_idx):\n",
    "        y_hat = self(data.x, data.edge_index, data.batch)\n",
    "        loss = self.loss(y_hat, data.y)\n",
    "        self.log('train_loss', loss, on_epoch=False, batch_size=self.batch_size, prog_bar=True, logger=True)\n",
    "        return loss\n",
    "\n",
    "    def validation_step(self, data, batch_idx):\n",
    "        y_hat = self(data.x, data.edge_index, data.batch)\n",
    "        loss = self.loss(y_hat, data.y)\n",
    "        self.log('val_loss', loss, on_epoch=True, batch_size=self.batch_size, prog_bar=True, logger=True)\n",
    "\n",
    "    def test_step(self, data, batch_idx):\n",
    "        y_hat = self(data.x, data.edge_index, data.batch)\n",
    "        # y_hat = torch.round(y_hat)\n",
    "        loss = self.loss(y_hat, data.y)\n",
    "        print('y_hat: ')\n",
    "        print(y_hat)\n",
    "        print('y: ')\n",
    "        print(data.y)\n",
    "        self.log('test_loss', loss, on_epoch=True, batch_size=self.batch_size, prog_bar=True, logger=True)\n",
    "\n",
    "    def predict_step(self, data, batch_idx):\n",
    "        pass\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        return torch.optim.Adam(self.parameters(), lr=self.lr)\n",
    "\n",
    "    def backward(self, loss, *args, **kwargs):\n",
    "        loss.backward()"
   ],
   "id": "4f3a4810aedd4e49",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-28T10:21:27.947399Z",
     "start_time": "2024-06-28T10:20:23.244525Z"
    }
   },
   "cell_type": "code",
   "source": [
    "if __name__ == '__main__':\n",
    "    torch.set_float32_matmul_precision('medium')\n",
    "    # list of datasets want to use\n",
    "    dataset = ['MUTAG']\n",
    "    # list of query graphs\n",
    "    query_graph = [nx.graph_atlas(14)]\n",
    "    # for qg in query_graph:\n",
    "    #     nx.draw(qg, with_labels=True, font_weight='bold')\n",
    "    batch_size = 512\n",
    "    datamodule = ENDataModule(dataset, query_graph, hop=nx.diameter(query_graph[0]), batch_s=batch_size, num_workers=8)\n",
    "    model = Model(in_channels=1, hidden_channels=64, out_channels=32, num_layers=3, dropout=0.1, batch_s=batch_size, lr=0.01)\n",
    "    logger = loggers.TensorBoardLogger('./', version=0)\n",
    "    trainer = pl.Trainer(max_epochs=10, accelerator='gpu', num_sanity_val_steps=0, logger=logger, log_every_n_steps=10, callbacks=[StochasticWeightAveraging(swa_lrs=1e-2)])\n",
    "    trainer.fit(model, datamodule)\n",
    "    trainer.test(ckpt_path='last', datamodule=datamodule)"
   ],
   "id": "bec92ef4ca5ee41e",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "C:\\Users\\27491\\anaconda3\\Lib\\site-packages\\pytorch_lightning\\callbacks\\model_checkpoint.py:652: Checkpoint directory ./lightning_logs\\version_0\\checkpoints exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name | Type   | Params | Mode \n",
      "----------------------------------------\n",
      "0 | gin  | GIN    | 15.7 K | train\n",
      "1 | slp  | MLP    | 64     | train\n",
      "2 | mlp  | MLP    | 3.3 K  | train\n",
      "3 | loss | L1Loss | 0      | train\n",
      "----------------------------------------\n",
      "19.1 K    Trainable params\n",
      "0         Non-trainable params\n",
      "19.1 K    Total params\n",
      "0.076     Total estimated model params size (MB)\n",
      "C:\\Users\\27491\\anaconda3\\Lib\\site-packages\\pytorch_lightning\\loops\\fit_loop.py:298: The number of training batches (4) is smaller than the logging interval Trainer(log_every_n_steps=10). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "490ba93fc2bd49ed8e6774a05690b0f6"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "678797416cdc41dcb062b5957d7ee149"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "fabf101340124964900be9c01399d77a"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "5345c1ef13ac45b38d6ed5f9284450f8"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "a6495aa272c24c2097c287de5fe91f56"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "0464d5645d17463db3738522dec05ac2"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "0b8c644b74b6458dac0f91bb36517f50"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "7097695fca864b9eb2c4484c5aae05ec"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "e156e52c8fd44fcb8c095a4bf172222b"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "10ea742460294a44b06c4bc2b2c07d63"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "118520911c6145dc9e0f352cc801a674"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "f246c609c9ba4bd1939cb8458a6d7750"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=11` reached.\n",
      "C:\\Users\\27491\\anaconda3\\Lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\checkpoint_connector.py:186: .test(ckpt_path=\"last\") is set, but there is no last checkpoint available. No checkpoint will be loaded. HINT: Set `ModelCheckpoint(..., save_last=True)`.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "C:\\Users\\27491\\anaconda3\\Lib\\site-packages\\pytorch_lightning\\utilities\\data.py:105: Total length of `DataLoader` across ranks is zero. Please make sure this was your intention.\n"
     ]
    }
   ],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-28T09:54:59.987808Z",
     "start_time": "2024-06-28T09:54:59.973912Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# display to tensorboard and show in the jupyter notebook\n",
    "%reload_ext tensorboard\n",
    "%tensorboard --logdir lightning_logs/"
   ],
   "id": "3ca676eec3f5fbc3",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Reusing TensorBoard on port 6006 (pid 29136), started 1:46:03 ago. (Use '!kill 29136' to kill it.)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-2574c2b1d7cb7a88\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-2574c2b1d7cb7a88\");\n",
       "          const url = new URL(\"/\", window.location);\n",
       "          const port = 6006;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-28T09:55:00.262295Z",
     "start_time": "2024-06-28T09:54:59.987808Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# visualize the model\n",
    "model = Model(in_channels=1, hidden_channels=64, out_channels=32, num_layers=1, dropout=0.1, batch_s=2, lr=0.01)\n",
    "x = torch.ones(2, 1)\n",
    "edge_index = torch.tensor([[0, 1],\n",
    "                           [0, 1]], dtype=torch.long)\n",
    "batch = torch.tensor([0, 1], dtype=torch.long)\n",
    "dot = make_dot(model(x, edge_index, batch), params=dict(model.named_parameters()))\n",
    "dot.view()"
   ],
   "id": "61a20310658db053",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Digraph.gv.pdf'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 6
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
